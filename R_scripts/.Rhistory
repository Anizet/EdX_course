?read.csv2() # semicolon separated values
?read.csv() # comma separated values
# functions available to read spreadsheet files
?read.table() # white space separated values
# functions available to read spreadsheet files
?read_table() # white space separated values
library(readxl)
#To check the beginning of a file
readLines("murders.csv", n_max = 3)
#To check the beginning of a file
read_lines("murders.csv", n_max = 3)
#To check the beginning of a file
readline("murders.csv", n_max = 3)
?read_line
?read_lines
library(tidyverse)
# functions available to read spreadsheet files
read_table() # white space separated values
#To check the beginning of a file
read_lines("murders.csv", n_max = 3)
# now :
dat <- read_csv(fullpath)
head(dat)
#Q14
read_lines("http://mlr.cs.umass.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data", nÂ°max = 3)
#Q14
read_lines("http://mlr.cs.umass.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data", n_max = 3)
read_lines(url, n_max = 3)
#Q14
url <- "http://mlr.cs.umass.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data"
read_lines(url, n_max = 3)
#Q14
url <- "https://raw.githubusercontent.com/rasbt/python-machine-learning-book/master/code/datasets/wdbc/wdbc.data"
read_lines(url, n_max = 3)
> #To move a file into the working directory
?read_csv
read_csv(url)
read_csv(url, col_names = FALSE)
head('gapminder')
library(dslabs)
data('gapminder')
head('gapminder')
head(gapminder)
str(gapminder)
tidy_data <- gapminder %>%
filter(country %in% c("South Korea", "Germany")) %>%
select(country, year, fertility)
library(dplyr)
tidy_data <- gapminder %>%
filter(country %in% c("South Korea", "Germany")) %>%
select(country, year, fertility)
tidy_data
str(tidy_data)
head(tidy_data)
library(readr)
library(tidyverse)
library(readr)
co2
co2_wide <- data.frame(matrix(co2, ncol = 12, byrow = TRUE)) %>%
setNames(1:12) %>%
mutate(year = as.character(1959:1997))
co2_wide
co2_tidy <- gather(-year, month, co2)
co2_tidy <- gather(co2_wide,-year, month, co2)
co2_tidy <- gather(co2_wide,month, co2, -year)
co2_tidy %>% ggplot(aes(as.numeric(month), co2, color = year)) + geom_line()
#q12
library(dslabs)
data(admissions)
dat <- admissions %>% select(-applicants)
head(dat)
tmp <- gather(admissions, key, value, admitted:applicants)
tmp
?slice
library(dplyr)
?slice
#Q5
library(Lahman)
install.packages(Lahman)
install.packages("Lahman")
#Q5
library(Lahman)
top <- Batting %>%
filter(yearID == 2016) %>%
arrange(desc(HR)) %>%
slice(1:10)
top %>% as_tibble()
Master %>% as_tibble()
top_names <- top %>% left_join(Master) %>%
select(playerID, nameFirst, nameLast, HR)
View(top_names)
View(top_names)
Salaries
head(Salaries)
str(Salaries)
str(AwardsPlayers)
AwardsPlayers %>% filter(yearID == 2016)
left_join(top, pouloulou)
pouloulou <- AwardsPlayers %>% filter(yearID == 2016)
left_join(top, pouloulou)
pouloulou <- AwardsPlayers %>% filter(yearID == 2016)
x <- left_join(top, pouloulou)
View(x)
View(x)
View(top)
v <- anti_join(top, pouloulou)
View(v)
View(x)
semi_join(top, pouloulou)
x <- semi_join(top, pouloulou)
View(x)
View(top)
anti_join(top, pouloulou)
v <- anti_join(top, pouloulou)
View(v)
View(top)
x <- intersect(top, pouloulou)
View(top)
View(top)
View(pouloulou)
View(v)
v <- inner_join(top, pouloulou)
View(v)
v <- anti_join(pouloulou, top)
View(x)
View(x)
View(v)
View(top_names)
View(top_names)
x <- semi_join(top, pouloulou)
v <- anti_join(pouloulou, top)
pouloulou <- AwardsPlayers %>% filter(yearID == 2016)
x <- semi_join(top, pouloulou)
v <- anti_join(pouloulou, top)
View(v)
View(v)
View(x)
library(tidyverse)
library(rvest)
source('~/R/R_scripts/Web_scraping.R', echo=TRUE)
tab <- h %>% html_nodes("table")
tab <- tab[[2]]
View(tab)
tab
# to make a data frame from a HTML table
tab <- tab %>% html_table
class(tab)
# to make a data frame from a HTML table
tab <- tab %>% html_table()
tab <- h %>% html_nodes("table")
tab <- tab[[2]]
# to make a data frame from a HTML table
tab <- tab %>% html_table()
class(tab)
View(tab)
View(tab)
tab <- tab %>% setNames(c("state", "population", "murders", "gun_murders", "gun_ownership", "total_rate", "murder_rate", "gun_murder_rate"))
head(tab)
head(tab)
?html_text
url <- "https://foodnetwork.co.uk/recipes/guacamole/?utm_source=foodnetwork.com&utm_medium=domestic"
h <- html_read(url)
library(tidyverse)
url <- "https://foodnetwork.co.uk/recipes/guacamole/?utm_source=foodnetwork.com&utm_medium=domestic"
h <- html_read(url)
h <- read_html(url)
library(tidyverse)
url <- "https://foodnetwork.co.uk/recipes/guacamole/?utm_source=foodnetwork.com&utm_medium=domestic"
h <- read_html(url)
h <- h %>% html_nodes(".ingredient") %>% html_text()
h
url <- "https://foodnetwork.co.uk/recipes/welsh-wine-goats-cheese-leek-and-parma-ham-tart/"
h <- read_html(url)
h <- h %>% html_nodes(".ingredient") %>% html_text()
h
get_recipe("https://foodnetwork.co.uk/rachel-khoos-simple-pleasures/rachel-khoos-mediterranean-vegetable-cannelloni/")
h }
h <- h %>% html_nodes(".ingredient") %>% html_text()
get_recipe <- function(url) {
h <- read_html(url)
h <- h %>% html_nodes(".ingredient") %>% html_text()
}
get_recipe("https://foodnetwork.co.uk/rachel-khoos-simple-pleasures/rachel-khoos-mediterranean-vegetable-cannelloni/")
h
get_recipe(https://foodnetwork.co.uk/recipes/quick-pulled-pork-tostadas/)
get_recipe("https://foodnetwork.co.uk/recipes/quick-pulled-pork-tostadas/")
get_recipe("https://foodnetwork.co.uk/recipes/quick-pulled-pork-tostadas/")
return(h)
View(get_recipe)
source('~/R/R_scripts/2nd_try_at_web_scrapping.R', echo=TRUE)
View(get_recipe)
get_recipe("https://foodnetwork.co.uk/recipes/quick-pulled-pork-tostadas/")
library(tidyverse)
url <- "https://www.reddit.com/"
h <- read_html(url)
h <- h %>% html_nodes("._eYtD2XCVieq6emjKBH3m") %>% html_text()
h
library(rvest)
url <- "https://web.archive.org/web/20181024132313/http://www.stevetheump.com/Payrolls.htm"
h <- read_html(url)
nodes <- html_nodes(h, "table")
html_text(nodes[[8]])
html_table(nodes[[8]])
html_table(nodes[[1:4]])
View(nodes)
html_table(nodes[[1]])
html_table(nodes[[1]])
html_table(nodes[[1]])
html_table(nodes[[2]])
html_table(nodes[[3]])
html_table(nodes[[4]])
sapply(nodes[1:4], html_table)
sapply(nodes[5:8], html_table)
sapply(nodes[6:8], html_table)
sapply(nodes[6:9], html_table)
sapply(nodes[19:21], html_table)
tab_1 <- html_table(nodes[[10]])
tab_2 <- html_table(nodes[[19]])
tab_1
tab_1 <- tab_1 %>% select("Team", "Payroll", 'Average')
tab_1 <- tab_1 %>% setNames(c("Team", "Payroll", 'Average'))%>% select("Team", "Payroll", 'Average')
tab_1 <- tab_1 %>% setNames(c("No.","Team", "Payroll", 'Average'))%>% select("Team", "Payroll", 'Average')
View(tab_1)
View(tab_1)
?slice
tab_1 <- tab_1 %>% slice( rows = 2:31)
View(tab_1)
View(tab_2)
tab_2 <- tab_2 %>% setNames(c("Team", "Payroll", "Average")) %>% slice(rows = 2:31)
?full_join
joined <- full_join(tab_1, tab_2, by = 'Teams')
joined <- full_join(tab_1, tab_2, by = 'Team')
tab <- html_nodes(tab, "tables")
url <- "https://en.wikipedia.org/w/index.php?title=Opinion_polling_for_the_United_Kingdom_European_Union_membership_referendum&oldid=896735054"
h <- read_html(url)
tab <- html_nodes(h, "tables")
url <- "https://en.wikipedia.org/w/index.php?title=Opinion_polling_for_the_United_Kingdom_European_Union_membership_referendum&oldid=896735054"
h <- read_html(url)
tab <- html_nodes(h, "table")
?html_table
sapply(tab[1:5], html_table)
sapply(tab[1:5], html_table, fill = TRUE)
sapply(tab[1:3], html_table, fill = TRUE)
tabby <- (tab[1:10], html_table, fill = TRUE)
tabby <- sapply(tab[1:10], html_table, fill = TRUE)
View(tabby)
View(tabby[[1]])
View(tabby[[2]])
View(tabby[[5]])
# To see what a string looks like
s <- '10"'
cat(s)
s <- '5\'10"'
cat(s)
(tidyverse)
library(tidyverse)
library(stringr)
?mutate_at
library(dslabs)
data(reported_heights)
# keep only entries that either result in NAs or are outside the plausible range of heights
not_inches <- function(x, smallest = 50, tallest = 84){
inches <- suppressWarnings(as.numeric(x))
ind <- is.na(inches) | inches < smallest | inches > tallest
ind
}
# number of problematic entries
problems <- reported_heights %>%
filter(not_inches(height)) %>%
.$height
library(dplyr)
library(tidyverse)
library(dplyr)
# keep only entries that either result in NAs or are outside the plausible range of heights
not_inches <- function(x, smallest = 50, tallest = 84){
inches <- suppressWarnings(as.numeric(x))
ind <- is.na(inches) | inches < smallest | inches > tallest
ind
}
# number of problematic entries
problems <- reported_heights %>%
filter(not_inches(height)) %>%
.$height
problems <- c("5.3", "5,5", "6 1", "5 .11", "5, 12")
library(tidyverse)
library(dplyr)
library(dslabs)
pattern_with_groups <- "^([4-7])[,\\.](\\d*)$"
str_replace(problems, pattern_with_groups, "\\1'\\2")
problems <- c("5.3", "5,5", "6 1", "5 .11", "5, 12")
pattern_with_groups <- "^([4-7])[,\\.\\s](\\d*)$"
str_replace(problems, pattern_with_groups, "\\1'\\2")
library(tidyverse)
library(stringr)
yes <- c("5", "6", "5")
no <- c("5'", "5''", "5'4")
s <- c(yes, no)
s
str_replace(s, "^([4-7])$", "\\1'0")
str_replace(s, "^([4-7])$", "\\1'0")
str_replace(s, "^([4-7])'?$", "\\1'0")
yes <- c("1,7", "1, 8", "2, " )
no <- c("5,8", "5,3,2", "1.7")
s <- c(yes, no)
str_replace(s, "^([12])\\s*,\\s*(\\d*)$", "\\1\\.\\2")
#there's a function for the specific purpose of trimming at the start or end of a string
str_trim("5 ' 9 ")
#there's also a specific function for upper to lowercase
s <- c("Five feet eight inches")
str_to_lower(s)
# To split a string into a character vector around a delimiter
library(purrr)
# To split a string into a character vector around a delimiter
library(tidyverse)
library(purrr)
?str_split
#example
filename <- system.file("extdata/murders.csv", package = "dslabs")
lines <- readLines(filename)
lines %>% head()
x <- str_split(lines, ",")
x %>% head()
col_names <- x[[1]]
x <- x[-1]
library(purrr)
map(x, function(y) y[1]) %>% head()
map(x, 1) %>% head()
?mutate_all
?parse_guess
map(x, function(x) x[1]) %>% head() # applies the same function to each elements of a list
research_funding_rates
library(dslabs)
data("research_funding_rates")
research_funding_rates
library("pdftools")
install.packages("pdftools")
library("pdftools")
temp_file <- tempfile()
url <- "http://www.pnas.org/content/suppl/2015/09/16/1510159112.DCSupplemental/pnas.201510159SI.pdf"
download.file(url, temp_file)
txt <- pdf_text(temp_file)
file.remove(temp_file)
txt
raw_data_research_funding_rates <- txt[2]
raw_data_research_funding_rates %>% head()
tab <- str_split(raw_data_research_funding_rates, "\n")
View(tab)
View(tab)
tab <- tab[[1]]
tab <- head()
tab %>% head()
tab <- str_split(raw_data_research_funding_rates, "\n")
tab <- tab[[1]]
tab %>% head()
the_names_1 <- tab[3]
the_names_2 <- tab[4]
the_names_1
the_names_1 <- the_names_1 %>%
str_trim() %>%
str_replace_all(",\\s.", "") %>%
str_split("\\s{2,}", simplify = TRUE)
the_names_1
the_names_2
the_names_2 <- the_names_2 %>%
str_trim() %>%
str_split("\\s+", simplify = TRUE)
the_names_2
?str_c
?rep
tmp_names <- str_c(rep(the_names_1, each = 3), the_names_2[-1], sep = "_")
the_names <- c(the_names_2[1], tmp_names) %>%
str_to_lower() %>%
str_replace_all("\\s", "_")
the_names
new_research_funding_rates %>% head()
new_research_funding_rates <- tab[6:14] %>%
str_trim %>%
str_split("\\s{2,}", simplify = TRUE) %>%
data.frame(stringsAsFactors = FALSE) %>%
setNames(the_names) %>%
mutate_at(-1, parse_number)
new_research_funding_rates %>% head()
library(dslabs)
data("research_funding_rates")
research_funding_rates
install.packages("pdftools")
install.packages("pdftools")
library("pdftools")
temp_file <- tempfile()
url <- "http://www.pnas.org/content/suppl/2015/09/16/1510159112.DCSupplemental/pnas.201510159SI.pdf"
download.file(url, temp_file)
txt <- pdf_text(temp_file)
file.remove(temp_file)
raw_data_research_funding_rates <- txt[2]
raw_data_research_funding_rates %>% head()
tab <- str_split(raw_data_research_funding_rates, "\n")
tab <- tab[[1]]
tab %>% head()
the_names_1 <- tab[3]
the_names_2 <- tab[4]
the_names_1
the_names_1 <- the_names_1 %>%
str_trim() %>%
str_replace_all(",\\s.", "") %>%
str_split("\\s{2,}", simplify = TRUE)
the_names_1
the_names_2
the_names_2 <- the_names_2 %>%
str_trim() %>%
str_split("\\s+", simplify = TRUE)
the_names_2
tmp_names <- str_c(rep(the_names_1, each = 3), the_names_2[-1], sep = "_")
the_names <- c(the_names_2[1], tmp_names) %>%
str_to_lower() %>%
str_replace_all("\\s", "_")
the_names
new_research_funding_rates <- tab[6:14] %>%
str_trim %>%
str_split("\\s{2,}", simplify = TRUE) %>%
data.frame(stringsAsFactors = FALSE) %>%
setNames(the_names) %>%
mutate_at(-1, parse_number)
library(dplyr)
library(dplyr)
library(tidyverse)
library(dslabs)
data("research_funding_rates")
research_funding_rates
library("pdftools")
temp_file <- tempfile()
url <- "http://www.pnas.org/content/suppl/2015/09/16/1510159112.DCSupplemental/pnas.201510159SI.pdf"
download.file(url, temp_file)
txt <- pdf_text(temp_file)
file.remove(temp_file)
raw_data_research_funding_rates <- txt[2]
raw_data_research_funding_rates %>% head()
tab <- str_split(raw_data_research_funding_rates, "\n")
tab <- tab[[1]]
tab %>% head()
the_names_1 <- tab[3]
the_names_2 <- tab[4]
the_names_1
the_names_1 <- the_names_1 %>%
str_trim() %>%
str_replace_all(",\\s.", "") %>%
str_split("\\s{2,}", simplify = TRUE)
the_names_1
the_names_2
the_names_2 <- the_names_2 %>%
str_trim() %>%
str_split("\\s+", simplify = TRUE)
the_names_2
tmp_names <- str_c(rep(the_names_1, each = 3), the_names_2[-1], sep = "_")
the_names <- c(the_names_2[1], tmp_names) %>%
str_to_lower() %>%
str_replace_all("\\s", "_")
the_names
new_research_funding_rates <- tab[6:14] %>%
str_trim %>%
str_split("\\s{2,}", simplify = TRUE) %>%
data.frame(stringsAsFactors = FALSE) %>%
setNames(the_names) %>%
mutate_at(-1, parse_number)
new_research_funding_rates %>% head()
identical(research_funding_rates, new_research_funding_rates)
library(tidyverse)
library(dslabs)
data("gapminder")
gapminder %>%
filter(region=="Caribbean") %>%
ggplot(aes(year, life_expectancy, color = country)) +
geom_line()
# recode long country names and remake plot
gapminder %>% filter(region=="Caribbean") %>%
mutate(country = recode(country,
'Antigua and Barbuda'="Barbuda",
'Dominican Republic' = "DR",
'St. Vincent and the Grenadines' = "St. Vincent",
'Trinidad and Tobago' = "Trinidad")) %>%
ggplot(aes(year, life_expectancy, color = country)) +
geom_line()
library(rvest)
library(tidyverse)
library(stringr)
url <- "https://en.wikipedia.org/w/index.php?title=Opinion_polling_for_the_United_Kingdom_European_Union_membership_referendum&oldid=896735054"
tab <- read_html(url) %>% html_nodes("table")
polls <- tab[[5]] %>% html_table(fill = TRUE)
View(polls)
View(polls)
polls <- polls %>% setNames((c("dates", "remain", "leave", "undecided", "lead", "samplesize", "pollster", "poll_type", "notes")))
#Q5
polls <- polls %>% setNames((c("dates", "remain", "leave", "undecided", "lead", "samplesize", "pollster", "poll_type", "notes"))) %>%
filter(str_detect(remain, "%") = TRUE)
#Q5
polls <- polls %>% setNames((c("dates", "remain", "leave", "undecided", "lead", "samplesize", "pollster", "poll_type", "notes"))) %>%
filter(str_detect(remain, "%"))
View(polls)
?parse_number
?stringr
polls <- polls %>% str_replace(undecided, NA, "0")
polls <- str_replace(polls$undecided, NA, "0")
polls <- str_replace(polls$undecided, "N/A", "0")
polls <- tab[[5]] %>% html_table(fill = TRUE)
#Q5
polls <- polls %>% setNames((c("dates", "remain", "leave", "undecided", "lead", "samplesize", "pollster", "poll_type", "notes"))) %>%
filter(str_detect(remain, "%"))
polls <- polls %>% mutate(undecided = str_replace(polls$undecided, "N/A", "0"))
polls <- polls %>% mutate(undecided = str_replace(polls$undecided, "N/A", "0%"))
polls <- polls %>% mutate(undecided = str_replace(polls$undecided, "N/A", "0%"))
View(polls)
View(polls)
View(polls)
